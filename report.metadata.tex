\def \codeURL{}
\def \codeDOI{}
\def \dataURL{}
\def \dataDOI{}
\def \editorNAME{}
\def \editorORCID{}
\def \reviewerINAME{}
\def \reviewerIORCID{}
\def \reviewerIINAME{}
\def \reviewerIIORCID{}
\def \dateRECEIVED{}
\def \dateACCEPTED{}
\def \datePUBLISHED{}
\def \articleTITLE{[Re] Bootstrap Your Own Latent: A new approach to self-supervised learning}
\def \articleTYPE{Replication}
\def \articleDOMAIN{Representation Learning}
\def \articleBIBLIOGRAPHY{bibliography.bib}
\def \articleYEAR{2023}
\def \reviewURL{}
\def \articleABSTRACT{This report outlines our attempt to reproduce BYOL, a self-supervised learning method designed to generate meaningful image representations by learning similar embeddings for pairs of synthetic image views. We specifically aimed to replicate results from the linear evaluation protocol on the CIFAR10 and ImageNet datasets. We employed the PyTorch framework and tailored our approach to Jean Zay's supercomputer, ensuring compatibility with multi-GPU, multi-node, and single GPU/CPU configurations. Our results are aligned with the original ones. Although the initial methodology was well articulated, making implementation straightforward, we encountered challenges in using the original optimizer, discerning unspecified implementation details, and aligning with high-performance computing infrastructure.}
\def \replicationCITE{}
\def \replicationBIB{}
\def \replicationURL{}
\def \replicationDOI{}
\def \contactNAME{Alexandre Devillers}
\def \contactEMAIL{alexandre.devillers@liris.cnrs.fr}
\def \articleKEYWORDS{BYOL, Slef-Supervised Learning, Visual Representation}
\def \journalNAME{ReScience C}
\def \journalVOLUME{}
\def \journalISSUE{}
\def \articleNUMBER{}
\def \articleDOI{}
\def \authorsFULL{Alexandre Devillers and Mathieu Lefort}
\def \authorsABBRV{A. Devillers and M. Lefort}
\def \authorsSHORT{Devillers and Lefort}
\title{\articleTITLE}
\date{}
\author[1]{Alexandre Devillers}
\author[1]{Mathieu Lefort}
\affil[1]{Univ Lyon, UCBL, CNRS, INSA Lyon, LIRIS, UMR5205, F-69622 Villeurbanne, France\\}

